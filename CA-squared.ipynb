{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA^2: *The Cultural Analytics of Cultural Analytics*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1: IPAM website\n",
    "\n",
    "Some early reconnoitering:\n",
    "\n",
    "URLs for the abstracts have the following form:\n",
    "\n",
    "```html\n",
    "http://www.ipam.ucla.edu/abstract/?tid=13443&pcode=CAWS1\n",
    "```\n",
    "\n",
    "Where the `tid` is some five-digit number in the 13000s and the `pcode` is CAWS1, CAWS2, CAWS3, and CAWS4.\n",
    "\n",
    "The abstracts are in `<p id=\"ctlAbstract\">`. \n",
    "\n",
    "\n",
    "## Attempt 2: from html files\n",
    "\n",
    "Authors are found in: \n",
    "\n",
    "```html\n",
    "<span id=\"abstractrpt_ctlAuthor_2\">\n",
    "```\n",
    "\n",
    "split on `-`: e.g., `Arnold, Taylor - Yale University`\n",
    "\n",
    "Abstracts are found in:\n",
    "\n",
    "```html\n",
    "<td id=\"abstractrpt_ctlabstract_2\" style=\"font-size:11pt; font-style:normal; width:795px;\"><p style=\"text-align:justify; display:block;\" id=\"ctlAbstract\" runat=\"server\">\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse(the_soup):\n",
    "    # get the author\n",
    "    author = the_soup.find('span', {'id' = 'abstractrpt_ctlAuthor_2'}).text\n",
    "    # get the abstract\n",
    "    abstract = the_soup.find('p', {'id' : 'ctlAbstract'}).text.strip('\\n')\n",
    "    return  abstract\n",
    "\n",
    "\n",
    "def to_txt(pth, out):\n",
    "    # open file to write to.\n",
    "    with open(out, \"w\") as out:\n",
    "        \n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"author\", \"title\", \"date\", \"length\", \"text\"])\n",
    "        # get all our html files.\n",
    "        for html in os.listdir(pth):\n",
    "            with open(os.path.join(pth, html)) as f:\n",
    "                # parse the file are write the data to a row.\n",
    "                wr.writerow(parse(BeautifulSoup(f, \"lxml\")))\n",
    "                \n",
    "to_csv(\"./test\",\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_csv(pth, out):\n",
    "    # open file to write to.\n",
    "    with open(out, \"w\") as out:\n",
    "        # create csv.writer. \n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"author\", \"title\", \"date\", \"length\", \"text\"])\n",
    "        # get all our html files.\n",
    "        for html in os.listdir(pth):\n",
    "            with open(os.path.join(pth, html)) as f:\n",
    "                # parse the file are write the data to a row.\n",
    "                wr.writerow(parse(BeautifulSoup(f, \"lxml\")))\n",
    "                \n",
    "to_csv(\"./test\",\"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
